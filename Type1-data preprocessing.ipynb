{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport time\nfrom tqdm import tqdm\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/data/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nrawImagePaths = glob('../input/data/images*/images/*.png')\nUSE_42GB = True\nif USE_42GB:\n    df = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")\nelse:\n    df = pd.read_csv(\"/kaggle/input/sample/sample_labels.csv\")\nprint('Number of Image Paths: ', len(rawImagePaths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.loc[:,'Finding Labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"label_counts = df['Finding Labels'].unique()\nlabel_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\n# df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nall_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n# df['Finding Labels']\nall_labels = [x for x in all_labels if len(x)>0]\n\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        df[c_label] = df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if USE_42GB:\n    rakeshSamplingConstant = 1200\n    df_42GB = pd.DataFrame()\n    for label in all_labels:\n        df_temp = df.loc[df['Finding Labels'].str.contains(label)]\n        if len(df_temp) >= rakeshSamplingConstant:\n            df_temp = df_temp.sample(rakeshSamplingConstant)\n            print(\"Obtained\", len(df_temp), \"\\trandom samples for label: \\t\", label)\n        else:\n            #gotta catchem all #pokemon\n            print(\"Obtained\", len(df_temp), \"\\tsamples for label: \\t\\t\", label)\n\n        df_42GB = pd.concat([df_42GB, df_temp],ignore_index=True)\n    df = df_42GB\n    print(\"Total new samples: \", len(df))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#link df to image, takes about 30 seconds\nmappedImagePaths = []\nif USE_42GB:\n    count = 0\n    start = time.time()\n    for imageName in df[\"Image Index\"]:\n        for path in rawImagePaths:\n            if imageName in path:\n                count+=1\n                mappedImagePaths.append(path);\n                #print (path, \"\\t\", imageName)\n                break\n    end = time.time()\n    print(end-start)\n    print (count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#verify propper mapping of panda df and the mapped image paths\nif USE_42GB:\n    for path, imageName in zip (mappedImagePaths, df[\"Image Index\"]):\n        print (path, imageName)\n        if (imageName not in path):\n            print(\"ERROR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['disease_vec'] = df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\ny=df['disease_vec']\ny[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_ = []\npath = \"/kaggle/input/sample/sample/images\"\nIMG_SIZE =100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_training_data_42GB():\n    i=0\n    for imgPath in tqdm(mappedImagePaths):\n        try:\n            #print (imgPath)\n            img_array1 = cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)  \n            new_array1 = cv2.resize(img_array1, (IMG_SIZE, IMG_SIZE))  \n            train_data_.append([new_array1,y[i]])  \n            i = i+1\n        except Exception as e: \n            pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_training_data1():\n    i=0\n    for img in tqdm(os.listdir(path)):\n        try:\n            img_array1 = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_array1 = cv2.resize(img_array1, (IMG_SIZE, IMG_SIZE))  \n            train_data_.append([new_array1,y[i]])  \n            i = i+1\n        except Exception as e: \n            pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if (USE_42GB):\n    create_training_data_42GB()\nelse:\n    create_training_data1()\n\nprint(len(train_data_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.shuffle(train_data_) \nprint(train_data_[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'xraydata'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outfile = open(filename,'wb')\npickle.dump(train_data_,outfile)\noutfile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"infile = open(filename,'rb')\nxraydatalist = pickle.load(infile)\ninfile.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------The End-------------------------------------------------------------\n\nAbove code is to generate pickle format "},{"metadata":{},"cell_type":"markdown","source":"Test Code for testing pickle format"},{"metadata":{"trusted":true},"cell_type":"code","source":"xraydatalist[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nY=[]\n\nfor i,j in xraydatalist:\n    X.append(i)\n    Y.append(j)\n\nX = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE, 1)\nX =X/255.0\nY = np.array(Y).astype(np.float32)\nindx = int(0.8*X.shape[0])\ntrainX, testX = X[:indx,:], X[indx:,:]\ntrainY, testY = Y[:indx,:], Y[indx:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testY.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = trainX.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n\n# model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n# model.add(MaxPooling2D(pool_size = 2))\n# model.add(Dropout(0.2))\n          \n# model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n# model.add(MaxPooling2D(pool_size = 2))\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 3))\nmodel.add(Dropout(0.2))\n\n# add in fully connected dense layers to model, then output classifiction probabilities using a sigmoid activation function\nmodel.add(Flatten())\nmodel.add(Dense(500, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(15, activation = 'sigmoid'))\n\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X, Y, batch_size=128, epochs=3, validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_Y = (model.predict(testX, batch_size = 64, verbose = True)>0.5 ).astype(int)\npred_Y[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve,accuracy_score\nmodel.evaluate(testX, testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\n# create plot\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (i, label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(testY[:,i].astype(int), pred_Y[:,i])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n\n# Set labels for plot\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('quick_trained_model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\ntest = xraydatalist[indx:]\neval= []\n\n\nfor i in range(10):\n    eval.append((testY[i], pred_Y[i], test[i][0]))\n    \nl=0\n\nfor i,j,k in eval:\n    print(\"actual:\",i,\" \",\"predicted:\",j)\n    plt.imshow(k, cmap='gray')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_,acc = model.evaluate(testX, testY,verbose=0)\nacc","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}